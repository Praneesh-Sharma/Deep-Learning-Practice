{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8ab74d25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the tensorflow APIs\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6f208d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences to tokenize\n",
    "train_sentences = [\n",
    "    'It is a sunny day',\n",
    "    'It is a cloudy day',\n",
    "    'Will it rain today?'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6898762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# instantiate the tokenizer\n",
    "tokenizer = Tokenizer(num_words=100)\n",
    "\n",
    "# train the tokenizer on training sentences\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "\n",
    "# store word index for the words in the sentences\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c2e47499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'it': 1, 'is': 2, 'a': 3, 'day': 4, 'sunny': 5, 'cloudy': 6, 'will': 7, 'rain': 8, 'today': 9}\n"
     ]
    }
   ],
   "source": [
    "print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b3f3141",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sequences using tokenizer\n",
    "sequences = tokenizer.texts_to_sequences(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2b588de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Index -->{'it': 1, 'is': 2, 'a': 3, 'day': 4, 'sunny': 5, 'cloudy': 6, 'will': 7, 'rain': 8, 'today': 9}\n",
      "Sequence of Words -->[[1, 2, 3, 5, 4], [1, 2, 3, 6, 4], [7, 1, 8, 9]]\n"
     ]
    }
   ],
   "source": [
    "#print word index dictionary and sequnces\n",
    "print(f\"Word Index -->{word_index}\")\n",
    "print(f\"Sequence of Words -->{sequences}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "1c4321bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a sunny day\n",
      "[1, 2, 3, 5, 4]\n"
     ]
    }
   ],
   "source": [
    "#print sample sentence and sequence\n",
    "print(train_sentences[0])\n",
    "print(sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5980542c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizing new data on the same tokenizer\n",
    "new_sentences = [\n",
    "    'Will it be raining today?',\n",
    "    'It is a pleasant day.'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9a1b48d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_sequences = tokenizer.texts_to_sequences(new_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2b0287ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Will it be raining today?', 'It is a pleasant day.']\n",
      "[[7, 1, 9], [1, 2, 3, 4]]\n"
     ]
    }
   ],
   "source": [
    "print(new_sentences)\n",
    "print(new_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b9a0e13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Replacing newly encountered words with special values\n",
    "\n",
    "# set up tokenizer again with oov_token\n",
    "tokenizer = Tokenizer(num_words=100, oov_token='<oov>')\n",
    "\n",
    "#train the new tokenizer on training sentences\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "\n",
    "#store word indexes for the words in the sentence\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a6477f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<oov>': 1, 'it': 2, 'is': 3, 'a': 4, 'day': 5, 'sunny': 6, 'cloudy': 7, 'will': 8, 'rain': 9, 'today': 10}\n",
      "['Will it be raining today?', 'It is a pleasant day.']\n",
      "[[8, 2, 1, 1, 10], [2, 3, 4, 1, 5]]\n"
     ]
    }
   ],
   "source": [
    "#create sequences of the new sentences\n",
    "new_sequences = tokenizer.texts_to_sequences(new_sentences)\n",
    "print(word_index)\n",
    "print(new_sentences)\n",
    "print(new_sequences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f03a1348",
   "metadata": {},
   "source": [
    "## Padding the Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "00f01de0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the APIs\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "52d964a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the train sentences\n",
    "train_sentences = [\n",
    "    'It will rain',\n",
    "    'The weather is cloudy',\n",
    "    'Will it be raining today?',\n",
    "    'It is a super hot day'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "85cf517c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train the tokenizer\n",
    "\n",
    "#set up the tokenizer again with the oov_token\n",
    "tokenizer = Tokenizer(num_words=100, oov_token='<oov>')\n",
    "\n",
    "#train the tokenizer on training sentences\n",
    "tokenizer.fit_on_texts(train_sentences)\n",
    "\n",
    "#store word index for the word in the sentence\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6cb6689e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create sequences\n",
    "sequences = tokenizer.texts_to_sequences(train_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "56411416",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pad sequences\n",
    "padded_seqs = pad_sequences(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3bea5252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<oov>': 1, 'it': 2, 'will': 3, 'is': 4, 'rain': 5, 'the': 6, 'weather': 7, 'cloudy': 8, 'be': 9, 'raining': 10, 'today': 11, 'a': 12, 'super': 13, 'hot': 14, 'day': 15}\n",
      "['It will rain', 'The weather is cloudy', 'Will it be raining today?', 'It is a super hot day']\n",
      "[[2, 3, 5], [6, 7, 4, 8], [3, 2, 9, 10, 11], [2, 4, 12, 13, 14, 15]]\n",
      "[[ 0  0  0  2  3  5]\n",
      " [ 0  0  6  7  4  8]\n",
      " [ 0  3  2  9 10 11]\n",
      " [ 2  4 12 13 14 15]]\n"
     ]
    }
   ],
   "source": [
    "print(word_index)\n",
    "print(train_sentences)\n",
    "print(sequences)\n",
    "print(padded_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cdccc353",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Customizing your padded sequence with parameters\n",
    "\n",
    "#pad sequences with padding type, max length and truncating parameters\n",
    "padded_seqs = pad_sequences(sequences,\n",
    "                            padding=\"post\",\n",
    "                            maxlen=5,\n",
    "                            truncating=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "87a85ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2  3  5  0  0]\n",
      " [ 6  7  4  8  0]\n",
      " [ 3  2  9 10 11]\n",
      " [ 2  4 12 13 14]]\n"
     ]
    }
   ],
   "source": [
    "print(padded_seqs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
